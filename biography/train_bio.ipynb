{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":2,"kernelspec":{"name":"python388jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37","display_name":"Python 3.8.8 64-bit"},"colab":{"name":"train_bio.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2cd8d20d57c4415d94c715d21389ad91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f3fbc49cc634412b030b9c99acf1107","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1dd6c796050a4b9c8d336ad48b7732a9","IPY_MODEL_af2a381d63e3406998815eda438b6596"]}},"5f3fbc49cc634412b030b9c99acf1107":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1dd6c796050a4b9c8d336ad48b7732a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_48e688c9babb4f0282edb5cc1531dd68","_dom_classes":[],"description":"Training:  94%","_model_name":"FloatProgressModel","bar_style":"danger","max":70,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":66,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9aa7089fcba0440d86fd9fe68f71cf5e"}},"af2a381d63e3406998815eda438b6596":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1f21419f217442868b396dbf2105d33d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 66/70 [14:45&lt;00:45, 11.48s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_486e84afce1b4c5697633583ec784372"}},"48e688c9babb4f0282edb5cc1531dd68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9aa7089fcba0440d86fd9fe68f71cf5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f21419f217442868b396dbf2105d33d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"486e84afce1b4c5697633583ec784372":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwOr5YYMV84d","executionInfo":{"status":"ok","timestamp":1616796771880,"user_tz":-180,"elapsed":4207,"user":{"displayName":"Сергей Исаев","photoUrl":"","userId":"16125203624123721798"}},"outputId":"1ea310ec-95b2-48bb-c224-fb0b2b168423"},"source":["# gptname = 'gpt2' #small\n","gptname = 'gpt2-large'\n","\n","colab = False\n","enablenews = True\n","external_save = False\n","enable_trash = False\n","\n","# large\n","lrmult = 0.5\n","# xl\n","# lrmult = 0.1\n","accumn = 10\n","devicename = 'cpu'\n","\n","if not colab:\n","    filepath = '.'\n","else:\n","    filepath = '/content/drive/MyDrive/bio'\n","    ! pip3 install transformers\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n"," \n","import sys\n","sys.path.append(filepath + '/utils')\n","sys.path.append(filepath + '/dataset')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVCW49weV84f","executionInfo":{"status":"ok","timestamp":1616796774401,"user_tz":-180,"elapsed":6721,"user":{"displayName":"Сергей Исаев","photoUrl":"","userId":"16125203624123721798"}}},"source":["import argparse, json, os, pickle, random, time, numpy as np, transformers, torch\n","\n","from transformers import GPT2Config, GPT2LMHeadModel,AdamW, GPT2Tokenizer\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm.notebook import tnrange, tqdm\n","\n","from utils import SummarizationDataset, FineTuningDataset, get_tokenizer, generate_sample, sample_seq, set_seed, top_k_top_p_filtering"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jCi7KZ5WeWW","executionInfo":{"status":"ok","timestamp":1616796774402,"user_tz":-180,"elapsed":6717,"user":{"displayName":"Сергей Исаев","photoUrl":"","userId":"16125203624123721798"}}},"source":["parser = argparse.ArgumentParser()\n","parser.add_argument(\"--lr\",default=5e-5, type=float, help=\"learning rate\")\n","parser.add_argument(\"--seed\",default=42, type=int,  help=\"seed to replicate results\")\n","parser.add_argument(\"--n_gpu\",default=1, type=int,  help=\"no of gpu available\")\n","parser.add_argument(\"--gradient_accumulation_steps\",default=10, type=int, help=\"gradient_accumulation_steps\")\n","parser.add_argument(\"--batch_size\",default=1, type=int,  help=\"batch_size\")\n","parser.add_argument(\"--num_workers\",default=2, type=int,  help=\"num of cpus available\")\n","parser.add_argument(\"--device\",default=torch.device(devicename), help=\"torch.device object\")\n","parser.add_argument(\"--num_train_epochs\",default=1, type=int,  help=\"no of epochs of training\")\n","if external_save:\n","    parser.add_argument(\"--model_dir\", default='D:/external_weights', type=str,  help=\"path to save trained model\")\n","else:\n","    parser.add_argument(\"--model_dir\",default= filepath + '/weights', type=str,  help=\"path to save trained model\")\n","parser.add_argument(\"--max_grad_norm\",default=1.0, type=float, help=\"max gradient norm.\")\n","parser.add_argument(\"--root_dir\",default= filepath + '/bignews/gpt2_1024_data', type=str, help=\"location of json dataset.\")\n","parser.add_argument(\"--ids_file\",default= filepath + '/bignews/ids.json', type=str, help=\"location of train, valid and test file indexes\")\n","args = parser.parse_args([])\n","\n","\n","if enablenews:\n","    strnews = 'ye'\n","else:\n","    strnews = 'no'\n","if enable_trash:\n","    str_trash = 'ye'\n","else:\n","    str_trash = 'no'\n","\n","model_text = '_bio_{}_lr{}_accum{}_{}news_{}trash'.format(gptname, int(lrmult*100), accumn, strnews, str_trash)\n","model_file = os.path.join(args.model_dir, 'model' + model_text + '.bin')\n","config_file = os.path.join(args.model_dir, 'config' + model_text + '.json')\n","log_file = os.path.join(args.model_dir, 'log' + model_text + '.txt')"],"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def evaluate(args, model, eval_dataset):\n","    sumloss = 0.0\n","    with torch.no_grad():\n","        model.eval()\n","        eval_dl = DataLoader(\n","            eval_dataset, batch_size=args.batch_size, num_workers=args.num_workers)\n","        loss_fct = CrossEntropyLoss()\n","        \n","        for batch in eval_dl:\n","            inputs, labels = batch['article'].to(args.device), batch['article'].to(args.device)\n","            logits = model(inputs)[0]\n","            shift_logits = logits[..., batch['sum_idx']:-1, :].contiguous()\n","            shift_labels = labels[..., batch['sum_idx']+1:].contiguous()\n","            sumloss += loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)).item()\n","\n","    return sumloss / len(eval_dataset)"]},{"cell_type":"code","metadata":{"id":"ujEjluwBWfmR","executionInfo":{"status":"ok","timestamp":1616796774402,"user_tz":-180,"elapsed":6712,"user":{"displayName":"Сергей Исаев","photoUrl":"","userId":"16125203624123721798"}}},"source":["def finetune(args, model, tokenizer, finetune_dataset, eval_dataset, model_file, config_file, log_file):\n","    loss_fct = CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=1*args.lr)\n","    scheduler = transformers.get_linear_schedule_with_warmup(\n","      optimizer, 0,\n","      2*len(finetune_dataset)*args.num_train_epochs//args.gradient_accumulation_steps)\n","    \n","    sumloss = 0.0\n","    log_text = ''\n","\n","    for epoch in range(args.num_train_epochs):\n","      train_sampler = RandomSampler(finetune_dataset)\n","      train_dl = DataLoader(\n","        finetune_dataset,sampler=train_sampler,\n","        batch_size=args.batch_size, num_workers=args.num_workers)\n","      model.zero_grad()\n","      set_seed(args)\n","      epoch_iterator = tqdm(train_dl, desc=\"Training\")\n","      for step, batch in enumerate(epoch_iterator):\n","        if step % 50 == 0:\n","          if step % args.gradient_accumulation_steps != 0:\n","            print(\"Gradient loss!!!\")\n","          \n","          log_add = 'Step: {}; validation loss: {}'.format(\n","            epoch*len(finetune_dataset) + step,\n","            evaluate(args, model, eval_dataset))\n","          log_text += log_add + '\\n'\n","          print(log_add)\n","          my_file = open(log_file, 'w')\n","          my_file.write(log_text)\n","          my_file.close()\n","\n","        inputs, labels = batch['article'].to(args.device), batch['article'].to(args.device)\n","\n","        # print(inputs.shape)\n","        # print(tokenizer.decode(list(inputs[0])))\n","\n","        model.train()\n","        logits = model(inputs)[0]\n","        shift_logits = logits[..., batch['sum_idx']:-1, :].contiguous()\n","        shift_labels = labels[..., batch['sum_idx']+1:].contiguous()\n","        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","        sumloss += float(loss.item())\n","        loss = loss/args.gradient_accumulation_steps\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","\n","        if (step + 1) % args.gradient_accumulation_steps == 0:\n","          optimizer.step()\n","          scheduler.step()  # Update learning rate schedule\n","          model.zero_grad()\n","              \n","        if (step + 1) % 10 == 0:\n","          log_add = 'Step: {}; loss: {}'.format(\n","            epoch*len(finetune_dataset)+step+1, sumloss/10)\n","          sumloss = 0.0\n","          log_text += log_add + '\\n'\n","          print(log_add)\n","          my_file = open(log_file, 'w')\n","          my_file.write(log_text)\n","          my_file.close()\n","    return log_text"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQb4uc0PXChv","executionInfo":{"status":"ok","timestamp":1616796806876,"user_tz":-180,"elapsed":39179,"user":{"displayName":"Сергей Исаев","photoUrl":"","userId":"16125203624123721798"}}},"source":["model_file_load = os.path.join(args.model_dir,  'model_data_summarization_{}_lr{}_accum{}.bin'.format(\n","          gptname, int(lrmult*100), accumn))\n","config_file_load = os.path.join(args.model_dir, 'config_data_summarization_{}_lr{}_accum{}.json'.format(\n","          gptname, int(lrmult*100), accumn))\n","\n","config = GPT2Config.from_json_file(config_file_load)\n","tokenizer = get_tokenizer(gptname)\n","model = GPT2LMHeadModel(config)\n","state_dict = torch.load(model_file_load, map_location=args.device)\n","_ = model.load_state_dict(state_dict)\n","_ = model.to(args.device)\n","print(len(FineTuningDataset(filepath + '/dataset', tokenizer, mode='train', addnews=enablenews)))\n","finetune_data = FineTuningDataset(filepath + '/dataset', tokenizer, mode='train', addnews=enablenews, length=200)\n","if enable_trash:\n","    trash_data = FineTuningDataset(filepath + '/dataset', tokenizer, mode='train', addnews=enablenews, length=320, trash=True)\n","eval_data = FineTuningDataset(filepath + '/dataset', tokenizer, mode='valid', addnews=enablenews, length=10)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["210\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":558,"referenced_widgets":["2cd8d20d57c4415d94c715d21389ad91","5f3fbc49cc634412b030b9c99acf1107","1dd6c796050a4b9c8d336ad48b7732a9","af2a381d63e3406998815eda438b6596","48e688c9babb4f0282edb5cc1531dd68","9aa7089fcba0440d86fd9fe68f71cf5e","1f21419f217442868b396dbf2105d33d","486e84afce1b4c5697633583ec784372"]},"id":"BjTg-vw7X38c","executionInfo":{"status":"error","timestamp":1616797693913,"user_tz":-180,"elapsed":926210,"user":{"displayName":"Сергей Исаев","photoUrl":"","userId":"16125203624123721798"}},"outputId":"a34f3e9e-b0a2-4898-940e-76c4c92e5de5"},"source":["start = time.time()\n","if enable_trash:\n","    finetune(\n","        args, model, tokenizer, trash_data, eval_data,\n","        model_file, config_file, log_file)\n","log_text = finetune(\n","    args, model, tokenizer, finetune_data, eval_data,\n","    model_file, config_file, log_file)\n","log_add = 'Step: {}; validation loss: {}'.format(\n","    args.num_train_epochs*len(finetune_data),\n","    evaluate(args, model, eval_data))\n","log_text += log_add + '\\n'\n","print(log_add)\n","time_text = 'Total time: {} minutes.'.format((time.time()-start)/60)\n","log_text += time_text + '\\n'\n","print(time_text)\n","my_file = open(log_file, 'w')\n","my_file.write(log_text)\n","my_file.close()\n","\n","print('Saving trained model...')\n","torch.save(model.state_dict(), model_file)\n","model.config.to_json_file(config_file)\n","print('Saved.')"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2044af6b83f8456d88952c6c9b42b992"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 0; validation loss: 2.3288988351821898\n","Step: 10; loss: 2.6168209314346313\n","Step: 20; loss: 2.359062874317169\n","Step: 30; loss: 2.162699830532074\n","Step: 40; loss: 2.169646167755127\n","Step: 50; loss: 1.985220766067505\n","Step: 50; validation loss: 1.9119152903556824\n","Step: 60; loss: 1.8769915580749512\n","Step: 70; loss: 2.479185664653778\n","Step: 80; loss: 2.359695041179657\n","Step: 90; loss: 2.193837809562683\n","Step: 100; loss: 2.1009088158607483\n","Step: 100; validation loss: 1.8933860540390015\n","Step: 110; loss: 2.024779903888702\n","Step: 120; loss: 1.9064692258834839\n","Step: 130; loss: 2.2020165085792542\n","Step: 140; loss: 2.167149066925049\n","Step: 150; loss: 2.0694161653518677\n","Step: 150; validation loss: 1.8712269067764282\n","Step: 160; loss: 1.911767065525055\n","Step: 170; loss: 2.0279907464981077\n","Step: 180; loss: 1.9029050827026368\n","Step: 190; loss: 2.080876326560974\n","Step: 200; loss: 1.92769775390625\n","Step: 200; validation loss: 1.8525607228279113\n","Total time: 224.24555460214614 minutes.\n","Saving trained model...\n","Saved.\n"]}]}]}